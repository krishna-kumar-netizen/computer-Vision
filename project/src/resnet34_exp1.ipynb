{"cells":[{"cell_type":"markdown","metadata":{"id":"THp6o6TfF2zS"},"source":["# Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"JvXYMcaPpG-W"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"AVvEX-3gpSVn"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pydicom\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/15/df16546bc59bfca390cf072d473fb2c8acd4231636f64356593a63137e55/pydicom-2.1.2-py3-none-any.whl (1.9MB)\n","\u001b[K     |████████████████████████████████| 1.9MB 5.6MB/s \n","\u001b[?25hInstalling collected packages: pydicom\n","Successfully installed pydicom-2.1.2\n","Collecting segmentation_models\n","  Downloading https://files.pythonhosted.org/packages/da/b9/4a183518c21689a56b834eaaa45cad242d9ec09a4360b5b10139f23c63f4/segmentation_models-1.0.1-py3-none-any.whl\n","Collecting keras-applications<=1.0.8,>=1.0.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 4.6MB/s \n","\u001b[?25hCollecting image-classifiers==1.0.0\n","  Downloading https://files.pythonhosted.org/packages/81/98/6f84720e299a4942ab80df5f76ab97b7828b24d1de5e9b2cbbe6073228b7/image_classifiers-1.0.0-py3-none-any.whl\n","Collecting efficientnet==1.0.0\n","  Downloading https://files.pythonhosted.org/packages/97/82/f3ae07316f0461417dc54affab6e86ab188a5a22f33176d35271628b96e0/efficientnet-1.0.0-py3-none-any.whl\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (2.10.0)\n","Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.19.5)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->segmentation_models) (0.16.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.15.0)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.1)\n","Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.4.1)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.2.2)\n","Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (7.0.0)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.5)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.1.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.3.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (0.10.0)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation_models) (4.4.2)\n","Installing collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\n","Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\n"]}],"source":["!pip3 install pydicom\n","!pip3 install segmentation_models\n","!pip3 install backbone-network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1e9MpSBmF5sE"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')\n","\n","import os\n","import cv2\n","import csv\n","import pickle\n","import pydicom\n","import numpy as np\n","import pandas as pd \n","from glob import glob\n","import keras\n","import tensorflow as tf\n","from keras import backend as K\n","\n","os.chdir('/content/drive/MyDrive/Initial-Code')\n","\n","from iou_dice_loss_functions import my_iou_metric, iou_metric_batch_val, bce_dice_loss\n","%env SM_FRAMEWORK=tf.keras\n","\n","from model_rle_functions import predict_result_val\n","from data_generator_functions import data_generator, label_generator\n","\n","import seg_models\n","keras.backend.set_image_data_format('channels_last')\n","\n","from keras.optimizers import SGD\n","from keras.callbacks import ModelCheckpoint\n","\n","import sys\n","sys.path.insert(0, 'siim-acr-pneumothorax-segmentation')\n","\n","seed = 1994\n","np.random.seed = seed\n","os.environ['PYTHONHASHSEED'] = str(seed)\n","tf.seed = seed"]},{"cell_type":"markdown","metadata":{"id":"eEU199y-GLtK"},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"uOLKytwdpCWz"},"outputs":[],"source":["# defining configuration parameters\n","org_size = 1024 # original image size\n","img_size = 256 # image resize size\n","batch_size = 40 # batch size for training unet"]},{"cell_type":"markdown","metadata":{"id":"lJcvxgVbjjYF"},"source":["## Load train and validation data from files"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"mGyAtfELguX1"},"outputs":[{"name":"stdout","output_type":"stream","text":["['../Dataset/stage1_sim/1.2.276.0.7230010.3.1.4.8323329.1702.1517875169.44421.dcm'\n"," '../Dataset/stage1_sim/1.2.276.0.7230010.3.1.4.8323329.5196.1517875186.906815.dcm'\n"," '../Dataset/stage1_sim/1.2.276.0.7230010.3.1.4.8323329.2310.1517875172.88826.dcm'\n"," ...\n"," '../Dataset/stage1_sim/1.2.276.0.7230010.3.1.4.8323329.6776.1517875201.61444.dcm'\n"," '../Dataset/stage1_sim/1.2.276.0.7230010.3.1.4.8323329.2039.1517875170.835799.dcm'\n"," '../Dataset/stage1_sim/1.2.276.0.7230010.3.1.4.8323329.10187.1517875222.531834.dcm']\n"]}],"source":["pkl_file_train = open('process_data/X_train.pkl', 'rb')\n","\n","X_train = pickle.load(pkl_file_train)\n","print(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XVlIQFjOgdkt"},"outputs":[],"source":["pkl_file_val = open('process_data/X_val.pkl', 'rb')\n","\n","X_val = pickle.load(pkl_file_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yefLxH_wgiuQ"},"outputs":[],"source":["pkl_file_masks = open('process_data/masks.pkl', 'rb')\n","\n","masks = pickle.load(pkl_file_masks)"]},{"cell_type":"markdown","metadata":{"id":"b_2eO3MjSUnJ"},"source":["## Data generation & Augmentations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V00rfTEyBGDz"},"outputs":[],"source":["import albumentations as A"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q-YK150LAmPi"},"outputs":[],"source":["training_augmentation = A.Compose([\n","    A.HorizontalFlip(p=0.5),\n","    A.OneOf([\n","        A.RandomContrast(),\n","        A.RandomGamma(),\n","        A.RandomBrightness(),\n","         ], p=0.3),\n","    A.OneOf([\n","        A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n","        A.GridDistortion(),\n","        A.OpticalDistortion(distort_limit=2, shift_limit=0.5),\n","        ], p=0.3),\n","    A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=20,\n","                                        interpolation=cv2.INTER_LINEAR, border_mode=cv2.BORDER_CONSTANT, p=1),\n","    A.RandomSizedCrop(min_max_height=(206,256), height=img_size, width=img_size,p=0.25)\n","],p=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3-aGAPOoxyqd"},"outputs":[],"source":["params_train = {'img_size': img_size,\n","          'batch_size': batch_size,\n","          \n","          'shuffle': True,\n","           'augmentations':training_augmentation,\n","           }\n","\n","params_val = {'img_size': img_size,\n","          'batch_size': batch_size,\n","          'n_channels': 1,\n","          'shuffle': True,\n","         }\n","\n","training_generator = data_generator(X_train, masks, **params_train)\n","validation_generator = data_generator(X_val, masks, **params_val)"]},{"cell_type":"markdown","metadata":{"id":"qXOOUV31S4Qv"},"source":["# Segmentation model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ekOt8Z8opCW3"},"outputs":[],"source":["K.clear_session()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nResy82lwhLY","scrolled":true},"outputs":[],"source":["BACKBONE = 'resnet34'\n","model = seg_models.Unet(backbone_name=BACKBONE, encoder_weights='imagenet')\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yhLeNifWpCW3"},"outputs":[],"source":["opt = SGD(momentum=0.9)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bs0g5lxppCW3"},"outputs":[],"source":["model.compile(optimizer=opt, loss=bce_dice_loss, metrics=[my_iou_metric])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7RXsdWdkr2q4"},"outputs":[],"source":["from swa import SWA\n","from annealing_scheduler_function import CosineAnnealingScheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GtGnqOHspCW4"},"outputs":[],"source":["epochs = 50\n","swa = SWA('model_output/512_resnet34_swa_exp1_stage1.model',45)\n","\n","callbacks = [\n","    ModelCheckpoint(\"model_output/512_resnet34_exp1_stage1.model\",monitor='val_loss', \n","                            mode = 'min', save_best_only=True,\n","                            verbose=1),\n","    swa,\n","    CosineAnnealingScheduler(T_max=epochs, eta_max=1e-3, eta_min=1e-5, verbose=1)\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b9iq0Q6epCW4"},"outputs":[],"source":["history = model.fit_generator(generator=training_generator,\n","                            validation_data=validation_generator,   \n","                           epochs=epochs, verbose=1,\n","                            callbacks=callbacks)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mCrdCrvfrl83"},"outputs":[],"source":["# list all data in history\n","import matplotlib.pyplot as plt\n"," \n","print(history.history.keys())\n","\n","# summarize history for iou\n","plt.figure(figsize=(20,5))\n","plt.subplot(1,2,1)\n","plt.plot(history.history['my_iou_metric'])\n","plt.plot(history.history['val_my_iou_metric'])\n","plt.title('model IOU')\n","plt.ylabel('iou')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'Validation'], loc='upper left')\n","\n","# summarize history for loss\n","plt.subplot(1,2,2)\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'Validation'], loc='upper left')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yCUB7-yu07o0"},"outputs":[],"source":["# Load best model or swa model\n","\n","model.load_weights('model_output/512_resnet34_swa_exp1_stage1.model')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hB3BCLOxp9FS"},"outputs":[],"source":["# defining configuration parameters\n","org_size = 1024 # original image size\n","img_size = 512# image resize size\n","batch_size = 10 # batch size for training unet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HFnMERiVqC3G"},"outputs":[],"source":["pkl_file_train = open('process_data/X_train.pkl', 'rb')\n","\n","X_train = pickle.load(pkl_file_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rXGrQwm-qQP9"},"outputs":[],"source":["pkl_file_val = open('process_data/X_val.pkl', 'rb')\n","\n","X_val = pickle.load(pkl_file_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vvJxUiYAqR8G"},"outputs":[],"source":["pkl_file_masks = open('process_data/masks.pkl', 'rb')\n","\n","masks = pickle.load(pkl_file_masks)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SVpbLr0jqSoA"},"outputs":[],"source":["import albumentations as A"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bfoiC1lKqUgc"},"outputs":[],"source":["training_augmentation = A.Compose([\n","    A.HorizontalFlip(p=0.5),\n","    A.OneOf([\n","        A.RandomContrast(),\n","        A.RandomGamma(),\n","        A.RandomBrightness(),\n","         ], p=0.3),\n","    A.OneOf([\n","        A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n","        A.GridDistortion(),\n","        A.OpticalDistortion(distort_limit=2, shift_limit=0.5),\n","        ], p=0.3),\n","    A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=20,\n","                                        interpolation=cv2.INTER_LINEAR, border_mode=cv2.BORDER_CONSTANT, p=1),\n","    A.RandomSizedCrop(min_max_height=(412, 512), height=img_size, width=img_size,p=0.25)\n","],p=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GpoSit03qWrd"},"outputs":[],"source":["params_train = {'img_size': img_size,\n","          'batch_size': batch_size,\n","          'n_channels': 3,\n","          'shuffle': True,\n","           'augmentations':training_augmentation,\n","           }\n","\n","params_val = {'img_size': img_size,\n","          'batch_size': batch_size,\n","          'n_channels': 3,\n","          'shuffle': True,\n","         }\n","\n","# Generators\n","training_generator = data_generator(X_train, masks, **params_train)\n","validation_generator = data_generator(X_val, masks, **params_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CkGckl-HPfuc"},"outputs":[],"source":["from swa import SWA\n","from annealing_scheduler_function import CosineAnnealingScheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a2jH5TcEPgkT"},"outputs":[],"source":["epochs = 60\n","swa = SWA('model_output/512_resnet34_swa_exp1_stage2.model',55)\n","\n","callbacks = [\n","    ModelCheckpoint(\"model_output/512_resnet34_exp1_stage2.model\",monitor='val_loss', \n","                            mode = 'min', save_best_only=True,\n","                            verbose=1),\n","    swa,\n","    CosineAnnealingScheduler(T_max=epochs, eta_max=1e-3, eta_min=1e-5, verbose=1)\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yFgHUKrzqbMM"},"outputs":[],"source":["history = model.fit_generator(generator=training_generator,\n","                            validation_data=validation_generator,   \n","                           epochs=epochs, verbose=1,\n","                            callbacks=callbacks) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9e-5gjQfPFzL"},"outputs":[],"source":["# list all data in history\n","import matplotlib.pyplot as plt\n"," \n","print(history.history.keys())\n","\n","# summarize history for iou\n","plt.figure(figsize=(20,5))\n","plt.subplot(1,2,1)\n","plt.plot(history.history['my_iou_metric'])\n","plt.plot(history.history['val_my_iou_metric'])\n","plt.title('model IOU')\n","plt.ylabel('iou')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'Validation'], loc='upper left')\n","\n","# summarize history for loss\n","plt.subplot(1,2,2)\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'Validation'], loc='upper left')"]},{"cell_type":"markdown","metadata":{"id":"tVzwLjvbpCW5"},"source":["# Evaluation validation data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mIhD4UL9vwzd"},"outputs":[],"source":["# Load best model or swa model\n","\n","model.load_weights('model_output/512_resnet34_swa_exp1_stage1.model')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eGICeoEGpCW5"},"outputs":[],"source":["params_val = {'img_size': img_size,\n","          'batch_size': 5,\n","          'n_channels': 3,\n","          'shuffle': False,\n","         }\n","\n","# Generators\n","validation_generator = data_generator(X_val, masks, **params_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x-hmCk8CpCW5"},"outputs":[],"source":["AUGMENTATIONS_TEST_FLIPPED = A.Compose([\n","    A.HorizontalFlip(p=1),\n","],p=1)\n","\n","params_val_flip = {'img_size': img_size,\n","          'batch_size': 5,\n","          'n_channels': 3,\n","          'shuffle': False,\n","        'augmentations':AUGMENTATIONS_TEST_FLIPPED,\n","         }\n","\n","validation_generator_flipped = data_generator(X_val, masks, **params_val_flip)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wz5iC9YzpCW6"},"outputs":[],"source":["preds_valid_orig = predict_result_val(model,validation_generator,img_size)\n","preds_valid_flipped = predict_result_val(model,validation_generator_flipped,img_size)\n","preds_valid_flipped = np.array([np.fliplr(x) for x in preds_valid_flipped])\n","preds_valid = 0.5*preds_valid_orig + 0.5*preds_valid_flipped"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O6ZEqwENpCW6"},"outputs":[],"source":["np.savez_compressed('process_data/val_pre/preds_valid_resnet34', array1= preds_valid)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ayA0LcXdpCW7"},"outputs":[],"source":["y_truth_val = label_generator(X_val, masks, len(preds_valid), img_size, 3)\n","\n","np.savez_compressed('process_data/val_pre/y_truth_val', array1= y_truth_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3yeEu9aXpCW7"},"outputs":[],"source":["decompressed_array= np.load(\"process_data/val_pre/y_truth_val.npz\")  \n","y_truth_val = decompressed_array['array1']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IY772Nq0pCW7"},"outputs":[],"source":["## Scoring for last model\n","score = 0.0\n","mask_area = 0\n","best_th = 0\n","\n","thresholds = np.arange(0.2, 0.9, 0.01) \n","areas = [1024, 2048, 3072, 4096]\n","for threshold in tqdm(thresholds):\n","    for area in tqdm(areas):\n","        iou = iou_metric_batch_val(y_truth_val, np.int32(preds_valid > threshold), area)\n","        if iou > score:\n","            score = iou\n","            mask_area = area\n","            best_th = threshold\n","            print(\"Threshold {}\\tMask area {}\\tIoU {}\".format(best_th, mask_area, score))\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"8OysmVw5uuL5"},"source":["# Evaluation validation data stage 2\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CL6McL7mv9xM"},"outputs":[],"source":["# Load best model or swa model\n","\n","model.load_weights('model_output/512_resnet34_swa_exp1_stage2.model')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZewszYrZu0pB"},"outputs":[],"source":["params_val = {'img_size': img_size,\n","          'batch_size': 5,\n","          'n_channels': 3,\n","          'shuffle': False,\n","         }\n","\n","# Generators\n","validation_generator = data_generator(X_val, masks, **params_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dTef94ocu5dr"},"outputs":[],"source":["AUGMENTATIONS_TEST_FLIPPED = A.Compose([\n","    A.HorizontalFlip(p=1),\n","],p=1)\n","\n","params_val_flip = {'img_size': img_size,\n","          'batch_size': 5,\n","          'n_channels': 3,\n","          'shuffle': False,\n","        'augmentations':AUGMENTATIONS_TEST_FLIPPED,\n","         }\n","\n","validation_generator_flipped = data_generator(X_val, masks, **params_val_flip)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ELd1HcRou7Sr"},"outputs":[],"source":["preds_valid_orig = predict_result_val(model,validation_generator,img_size)\n","preds_valid_flipped = predict_result_val(model,validation_generator_flipped,img_size)\n","preds_valid_flipped = np.array([np.fliplr(x) for x in preds_valid_flipped])\n","preds_valid = 0.5*preds_valid_orig + 0.5*preds_valid_flipped"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P7RpT3jBu9AY"},"outputs":[],"source":["np.savez_compressed('process_data/val_pre/preds_valid_resnet34', array1= preds_valid)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jQiPdyTdu-tJ"},"outputs":[],"source":["y_truth_val = label_generator(X_val, masks, len(preds_valid), img_size, 3)\n","\n","np.savez_compressed('process_data/val_pre/y_truth_val', array1= y_truth_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lk4xzOXkvAdu"},"outputs":[],"source":["decompressed_array= np.load(\"process_data/val_pre/y_truth_val.npz\")  \n","y_truth_val = decompressed_array['array1']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xt9bi_SevB-u"},"outputs":[],"source":["## Scoring for last model\n","score = 0.0\n","mask_area = 0\n","best_th = 0\n","\n","thresholds = np.arange(0.2, 0.9, 0.01) \n","areas = [1024, 2048, 3072, 4096]\n","for threshold in tqdm(thresholds):\n","    for area in tqdm(areas):\n","        iou = iou_metric_batch_val(y_truth_val, np.int32(preds_valid > threshold), area)\n","        if iou > score:\n","            score = iou\n","            mask_area = area\n","            best_th = threshold\n","            print(\"Threshold {}\\tMask area {}\\tIoU {}\".format(best_th, mask_area, score))\n","    print()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"resnet50_exp1.ipynb","version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}