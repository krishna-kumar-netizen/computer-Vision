{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet50.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THp6o6TfF2zS"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvXYMcaPpG-W"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVvEX-3gpSVn"
      },
      "source": [
        "!pip3 install pydicom\n",
        "!pip3 install segmentation_models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e9MpSBmF5sE"
      },
      "source": [
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import csv\n",
        "import pickle\n",
        "import pydicom\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "from glob import glob\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/Initial-Code')\n",
        "#os.chdir('./Initial-Code')\n",
        "\n",
        "# import the necessary packages\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "\n",
        "from dataset import prepare_data\n",
        "from metric_loss import my_iou_metric, iou_metric_batch_val, bce_dice_loss\n",
        "%env SM_FRAMEWORK=tf.keras\n",
        "\n",
        "from predict import predict_result_val, prepare_test, get_test, get_prediction, get_rles\n",
        "from generator import DataGenerator, label_generator\n",
        "\n",
        "import seg_models\n",
        "keras.backend.set_image_data_format('channels_last')\n",
        "\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, 'siim-acr-pneumothorax-segmentation')\n",
        "from mask_functions import rle2mask, mask2rle\n",
        "#X\n",
        "## Seeding \n",
        "seed = 1994\n",
        "np.random.seed = seed\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "tf.seed = seed\n",
        "\n",
        "import gc   #Gabage collector for cleaning deleted data from memory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFPLTkpxpCWy"
      },
      "source": [
        "#!pip3 install pydicom\n",
        "#!pip3 install keras\n",
        "#!pip3 install tensorflow\n",
        "#!pip3 install sklearn\n",
        "#!pip3 install segmentation_models\n",
        "#!pip3 install generic_utils\n",
        "\n",
        "#!pip3 install  albumentations\n",
        "!pip3 install backbone-network"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEU199y-GLtK"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOLKytwdpCWz"
      },
      "source": [
        "# defining configuration parameters\n",
        "org_size = 1024 # original image size\n",
        "img_size = 256 # image resize size\n",
        "batch_size = 10 # batch size for training unet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJcvxgVbjjYF"
      },
      "source": [
        "## Load train and validation data from files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGyAtfELguX1"
      },
      "source": [
        "pkl_file_train = open('process_data/X_train.pkl', 'rb')\n",
        "\n",
        "X_train = pickle.load(pkl_file_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVlIQFjOgdkt"
      },
      "source": [
        "pkl_file_val = open('process_data/X_val.pkl', 'rb')\n",
        "\n",
        "X_val = pickle.load(pkl_file_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yefLxH_wgiuQ"
      },
      "source": [
        "pkl_file_masks = open('process_data/masks.pkl', 'rb')\n",
        "\n",
        "masks = pickle.load(pkl_file_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_2eO3MjSUnJ"
      },
      "source": [
        "## Data generation & Augmentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V00rfTEyBGDz"
      },
      "source": [
        "import albumentations as A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-YK150LAmPi"
      },
      "source": [
        "training_augmentation = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.OneOf([\n",
        "        #A.CLAHE(),\n",
        "        A.RandomContrast(),\n",
        "        A.RandomGamma(),\n",
        "        A.RandomBrightness(),\n",
        "         ], p=0.3),\n",
        "    A.OneOf([\n",
        "        A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
        "        A.GridDistortion(),\n",
        "        A.OpticalDistortion(distort_limit=2, shift_limit=0.5),\n",
        "        ], p=0.3),\n",
        "    A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=20,\n",
        "                                        interpolation=cv2.INTER_LINEAR, border_mode=cv2.BORDER_CONSTANT, p=1),\n",
        "    A.RandomSizedCrop(min_max_height=(206,256), height=img_size, width=img_size,p=0.25)\n",
        "],p=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-aGAPOoxyqd"
      },
      "source": [
        "params_train = {'img_size': img_size,\n",
        "          'batch_size': batch_size,\n",
        "          'n_channels': 3,\n",
        "          'shuffle': True,\n",
        "           'augmentations':training_augmentation,\n",
        "           }\n",
        "\n",
        "params_val = {'img_size': img_size,\n",
        "          'batch_size': batch_size,\n",
        "          'n_channels': 3,\n",
        "          'shuffle': True,\n",
        "         }\n",
        "\n",
        "# Generators\n",
        "training_generator = DataGenerator(X_train, masks, **params_train)\n",
        "validation_generator = DataGenerator(X_val, masks, **params_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYf50HgCyOo3"
      },
      "source": [
        "x, y = training_generator.__getitem__(0)\n",
        "print(x.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXOOUV31S4Qv"
      },
      "source": [
        "# Segmentation model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekOt8Z8opCW3"
      },
      "source": [
        "K.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nResy82lwhLY",
        "scrolled": true
      },
      "source": [
        "BACKBONE = 'resnet50'\n",
        "model = seg_models.Unet(backbone_name=BACKBONE, encoder_weights='imagenet') #, decoder_use_batchnorm=False)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AkA-wbF1KhB"
      },
      "source": [
        "# From: https://github.com/jocicmarko/ultrasound-nerve-segmentation/blob/master/train.py\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = tf.keras.layers.flatten(y_true)\n",
        "    y_pred_f = tf.keras.layers.flatten(y_pred)\n",
        "    intersection = keras.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + 1) / (keras.sum(y_true_f) + keras.sum(y_pred_f) + 1)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)\n",
        "\n",
        "def unet(input_size=(256,256,1)):\n",
        "    \n",
        "    inputs = Input(input_size)\n",
        "    \n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
        "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
        "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
        "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
        "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
        "\n",
        "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
        "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
        "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
        "\n",
        "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
        "\n",
        "    return Model(inputs=[inputs], outputs=[conv10])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhLeNifWpCW3"
      },
      "source": [
        "opt = SGD(momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bs0g5lxppCW3"
      },
      "source": [
        "model.compile(optimizer=opt, loss=bce_dice_loss, metrics=[my_iou_metric])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RXsdWdkr2q4"
      },
      "source": [
        "from swa import SWA\n",
        "from cosine_schedule import CosineAnnealingScheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtGnqOHspCW4"
      },
      "source": [
        "epochs = 60\n",
        "swa = SWA('model_output/512_resnet50_swa.model',55)\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\"model_output/512_resnet50.model\",monitor='val_loss', \n",
        "                            mode = 'min', save_best_only=True,\n",
        "                            verbose=1),\n",
        "    swa,\n",
        "    CosineAnnealingScheduler(T_max=epochs, eta_max=1e-3, eta_min=1e-5, verbose=1)\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9iq0Q6epCW4"
      },
      "source": [
        "history = model.fit_generator(generator=training_generator,\n",
        "                            validation_data=validation_generator,   \n",
        "                           epochs=epochs, verbose=1,\n",
        "                            callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCrdCrvfrl83"
      },
      "source": [
        "# list all data in history\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "print(history.history.keys())\n",
        "\n",
        "# summarize history for iou\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['my_iou_metric'])\n",
        "plt.plot(history.history['val_my_iou_metric'])\n",
        "plt.title('model IOU')\n",
        "plt.ylabel('iou')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'Validation'], loc='upper left')\n",
        "\n",
        "# summarize history for loss\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'Validation'], loc='upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCUB7-yu07o0"
      },
      "source": [
        "# Load best model or swa model\n",
        "\n",
        "model.load_weights('model_output/512_resnet50_swa.model')\n",
        "\n",
        "#print('using best weight model')\n",
        "#model.load_weights('stage2_model_output/256_resnet34.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hB3BCLOxp9FS"
      },
      "source": [
        "# defining configuration parameters\n",
        "org_size = 1024 # original image size\n",
        "img_size = 512# image resize size\n",
        "batch_size = 10 # batch size for training unet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFnMERiVqC3G"
      },
      "source": [
        "pkl_file_val = open('process_data/X_val.pkl', 'rb')\n",
        "\n",
        "X_val = pickle.load(pkl_file_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXGrQwm-qQP9"
      },
      "source": [
        "pkl_file_val = open('process_data/X_val.pkl', 'rb')\n",
        "\n",
        "X_val = pickle.load(pkl_file_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvJxUiYAqR8G"
      },
      "source": [
        "pkl_file_masks = open('process_data/masks.pkl', 'rb')\n",
        "\n",
        "masks = pickle.load(pkl_file_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVpbLr0jqSoA"
      },
      "source": [
        "import albumentations as A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfoiC1lKqUgc"
      },
      "source": [
        "training_augmentation = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.OneOf([\n",
        "        #A.CLAHE(),\n",
        "        A.RandomContrast(),\n",
        "        A.RandomGamma(),\n",
        "        A.RandomBrightness(),\n",
        "         ], p=0.3),\n",
        "    A.OneOf([\n",
        "        A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
        "        A.GridDistortion(),\n",
        "        A.OpticalDistortion(distort_limit=2, shift_limit=0.5),\n",
        "        ], p=0.3),\n",
        "    A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=20,\n",
        "                                        interpolation=cv2.INTER_LINEAR, border_mode=cv2.BORDER_CONSTANT, p=1),\n",
        "    A.RandomSizedCrop(min_max_height=(412, 512), height=img_size, width=img_size,p=0.25)\n",
        "],p=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpoSit03qWrd"
      },
      "source": [
        "params_train = {'img_size': img_size,\n",
        "          'batch_size': batch_size,\n",
        "          'n_channels': 3,\n",
        "          'shuffle': True,\n",
        "           'augmentations':training_augmentation,\n",
        "           }\n",
        "\n",
        "params_val = {'img_size': img_size,\n",
        "          'batch_size': batch_size,\n",
        "          'n_channels': 3,\n",
        "          'shuffle': True,\n",
        "         }\n",
        "\n",
        "# Generators\n",
        "training_generator = DataGenerator(X_train, masks, **params_train)\n",
        "validation_generator = DataGenerator(X_val, masks, **params_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWtyoAf8qYxE"
      },
      "source": [
        "x, y = training_generator.__getitem__(0)\n",
        "print(x.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkGckl-HPfuc"
      },
      "source": [
        "from swa import SWA\n",
        "from cosine_schedule import CosineAnnealingScheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2jH5TcEPgkT"
      },
      "source": [
        "epochs = 60\n",
        "swa = SWA('model_output/512_resnet50_swa_stage2.model',55)\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\"model_output/512_resnet50_stage2.model\",monitor='val_loss', \n",
        "                            mode = 'min', save_best_only=True,\n",
        "                            verbose=1),\n",
        "    swa,\n",
        "    CosineAnnealingScheduler(T_max=epochs, eta_max=1e-3, eta_min=1e-5, verbose=1)\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFgHUKrzqbMM"
      },
      "source": [
        "history = model.fit_generator(generator=training_generator,\n",
        "                            validation_data=validation_generator,   \n",
        "                           epochs=epochs, verbose=1,\n",
        "                            callbacks=callbacks) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e-5gjQfPFzL"
      },
      "source": [
        "# list all data in history\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "print(history.history.keys())\n",
        "\n",
        "# summarize history for iou\n",
        "plt.figure(figsize=(20,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(history.history['my_iou_metric'])\n",
        "plt.plot(history.history['val_my_iou_metric'])\n",
        "plt.title('model IOU')\n",
        "plt.ylabel('iou')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'Validation'], loc='upper left')\n",
        "\n",
        "# summarize history for loss\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'Validation'], loc='upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVzwLjvbpCW5"
      },
      "source": [
        "# Evaluation validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGICeoEGpCW5"
      },
      "source": [
        "params_val = {'img_size': img_size,\n",
        "          'batch_size': 5,\n",
        "          'n_channels': 3,\n",
        "          'shuffle': False,\n",
        "         }\n",
        "\n",
        "# Generators\n",
        "validation_generator = DataGenerator(X_val, masks, **params_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-hmCk8CpCW5"
      },
      "source": [
        "AUGMENTATIONS_TEST_FLIPPED = A.Compose([\n",
        "    A.HorizontalFlip(p=1),\n",
        "],p=1)\n",
        "\n",
        "params_val_flip = {'img_size': img_size,\n",
        "          'batch_size': 5,\n",
        "          'n_channels': 3,\n",
        "          'shuffle': False,\n",
        "        'augmentations':AUGMENTATIONS_TEST_FLIPPED,\n",
        "         }\n",
        "\n",
        "validation_generator_flipped = DataGenerator(X_val, masks, **params_val_flip)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz5iC9YzpCW6"
      },
      "source": [
        "preds_valid_orig = predict_result(model,validation_generator,img_size)\n",
        "preds_valid_flipped = predict_result(model,validation_generator_flipped,img_size)\n",
        "preds_valid_flipped = np.array([np.fliplr(x) for x in preds_valid_flipped])\n",
        "preds_valid = 0.5*preds_valid_orig + 0.5*preds_valid_flipped"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6ZEqwENpCW6"
      },
      "source": [
        "np.savez_compressed('process_data/val_pre/preds_valid_resnet50', array1= preds_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayA0LcXdpCW7"
      },
      "source": [
        "y_truth_val = label_generator(X_val, masks, len(preds_valid), img_size, 3)\n",
        "\n",
        "np.savez_compressed('process_data/val_pre/y_truth_val', array1= y_truth_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yeEu9aXpCW7"
      },
      "source": [
        "decompressed_array= np.load(\"process_data/val_pre/y_truth_val.npz\")  \n",
        "y_truth_val = decompressed_array['array1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY772Nq0pCW7"
      },
      "source": [
        "## Scoring for last model\n",
        "score = 0.0\n",
        "mask_area = 0\n",
        "best_th = 0\n",
        "\n",
        "thresholds = np.arange(0.2, 0.9, 0.01) \n",
        "areas = [1024, 2048, 3072, 4096]\n",
        "for threshold in tqdm(thresholds):\n",
        "    for area in tqdm(areas):\n",
        "        iou = iou_metric_batch_val(y_truth_val, np.int32(preds_valid > threshold), area)\n",
        "        if iou > score:\n",
        "            score = iou\n",
        "            mask_area = area\n",
        "            best_th = threshold\n",
        "            print(\"Threshold {}\\tMask area {}\\tIoU {}\".format(best_th, mask_area, score))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2CzRZkloprR"
      },
      "source": [
        "# Test Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQOo2RTApCW8"
      },
      "source": [
        "test_file = 'stage2_siim_data/stage_2_images/*.dcm'\n",
        "test_metadata_df = prepare_test(test_file, rle_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrvBZNfITeyX"
      },
      "source": [
        "test_data = get_test(3205, test_metadata_df, img_size=img_size, channels=3) #0, 1068, 2136, 3205\n",
        "print(test_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pexJuAi3pCW8"
      },
      "source": [
        "resnet50_512_pred_test = get_prediction(model, test_data, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VArhxumpCW8"
      },
      "source": [
        "np.savez_compressed('process_data/test_pre/resnet50_512_pred_test', array1= resnet50_512_pred_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFIDTEfPpCW9"
      },
      "source": [
        "decompressed_array= np.load(\"process_data/test_pre/resnet50_512_pred_test.npz\")  \n",
        "resnet50_512_pred_test = decompressed_array['array1']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-Ef-zcgpCW9"
      },
      "source": [
        "rles = get_rles(preds_test, b_th = 0.73, r_th = 2048)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EXCbHnmpCW9"
      },
      "source": [
        "test_fn = sorted(glob('stage2_siim_data/stage_2_images/*.dcm'))\n",
        "test_IDs = [o.split('/')[-1][:-4] for o in test_fn]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98PMy6EAb9zB"
      },
      "source": [
        "sub_df = pd.DataFrame({'ImageId': test_IDs, 'EncodedPixels': rles})\n",
        "sub_df.loc[sub_df.EncodedPixels=='', 'EncodedPixels'] = '-1'\n",
        "sub_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKu1ZrZtcKCb"
      },
      "source": [
        "sub_df.to_csv('model_submission/resnet50_submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nSv4P6m92fX"
      },
      "source": [
        "sub_df['EncodedPixels'].value_counts(normalize=True) * 100"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}