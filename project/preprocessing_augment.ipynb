{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bit9c06a3810a8049cb8a4e4c93d687f07a",
   "display_name": "Python 3.8.5 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import pickle\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from glob import glob\n",
    "\n",
    "\n",
    "# import the necessary packages\n",
    "# import keras\n",
    "# import tensorflow as tf\n",
    "# from keras import backend as K\n",
    "\n",
    "from dataset import prepare_data\n",
    "from generator import DataGenerator, label_generator\n",
    "# from metric_loss import my_iou_metric, iou_metric_batch_val, bce_dice_loss\n",
    "# from predict import predict_result_val, prepare_test, get_test, get_prediction, get_rles\n",
    "\n",
    "# import seg_models\n",
    "# keras.backend.set_image_data_format('channels_last')\n",
    "\n",
    "# from keras.optimizers import SGD\n",
    "# from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, 'siim-acr-pneumothorax-segmentation')\n",
    "from mask_functions import rle2mask, mask2rle\n",
    "\n",
    "## Seeding \n",
    "seed = 1994\n",
    "np.random.seed = seed\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "# tf.seed = seed\n",
    "\n",
    "import gc   #Gabage collector for cleaning deleted data from memory"
   ]
  },
  {
   "source": [
    "# Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining configuration parameters\n",
    "org_size = 1024 # original image size\n",
    "img_size = 512  # image resize size\n",
    "batch_size = 10 # batch size for training unet"
   ]
  },
  {
   "source": [
    "## Load train and validation data from files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file_train = open('process_data/X_train.pkl', 'rb')\n",
    "\n",
    "X_train = pickle.load(pkl_file_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file_val = open('process_data/X_val.pkl', 'rb')\n",
    "\n",
    "X_val = pickle.load(pkl_file_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_file_masks = open('process_data/masks.pkl', 'rb')\n",
    "\n",
    "masks = pickle.load(pkl_file_masks)"
   ]
  },
  {
   "source": [
    "## Data generation & Augmentations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_augmentation = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.OneOf([\n",
    "        #A.CLAHE(),\n",
    "        A.RandomContrast(),\n",
    "        A.RandomGamma(),\n",
    "        A.RandomBrightness(),\n",
    "         ], p=0.3),\n",
    "    A.OneOf([\n",
    "        A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n",
    "        A.GridDistortion(),\n",
    "        A.OpticalDistortion(distort_limit=2, shift_limit=0.5),\n",
    "        ], p=0.3),\n",
    "    A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=20,\n",
    "                                        interpolation=cv2.INTER_LINEAR, border_mode=cv2.BORDER_CONSTANT, p=1),\n",
    "    A.RandomSizedCrop(min_max_height=(img_size, img_size), height=img_size, width=img_size,p=0.25)\n",
    "],p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_train = {'img_size': img_size,\n",
    "          'batch_size': batch_size,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': True,\n",
    "           'augmentations':training_augmentation,\n",
    "           }\n",
    "\n",
    "params_val = {'img_size': img_size,\n",
    "          'batch_size': batch_size,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': True,\n",
    "         }\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(X_train, masks, **params_train)\n",
    "validation_generator = DataGenerator(X_val, masks, **params_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10, 512, 512, 3) (10, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "x, y = training_generator.__getitem__(0)\n",
    "print(x.shape, y.shape)"
   ]
  }
 ]
}